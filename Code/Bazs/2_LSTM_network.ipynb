{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('PreprocessedData_v2.txt',\n",
    "                               sep='\\t',\n",
    "                               decimal=',')\n",
    "header = df.columns\n",
    "df_arr =np.array(df, dtype='float64')\n",
    "df =pd.DataFrame(df_arr, columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta_t</th>\n",
       "      <th>acc0</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>gyro0</th>\n",
       "      <th>gyro1</th>\n",
       "      <th>gyro2</th>\n",
       "      <th>mag0</th>\n",
       "      <th>mag1</th>\n",
       "      <th>mag2</th>\n",
       "      <th>...</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>beta</th>\n",
       "      <th>Qx</th>\n",
       "      <th>Qy</th>\n",
       "      <th>Qz</th>\n",
       "      <th>Qw</th>\n",
       "      <th>delta_x</th>\n",
       "      <th>delta_y</th>\n",
       "      <th>delta_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>-0.0022</td>\n",
       "      <td>-0.5292</td>\n",
       "      <td>-0.6538</td>\n",
       "      <td>-0.5275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.402</td>\n",
       "      <td>-0.0129</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0891</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0085</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>-0.5292</td>\n",
       "      <td>-0.6538</td>\n",
       "      <td>-0.4945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.402</td>\n",
       "      <td>-0.0128</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0810</td>\n",
       "      <td>-0.0039</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0199</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.5162</td>\n",
       "      <td>-0.6538</td>\n",
       "      <td>-0.5275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.402</td>\n",
       "      <td>-0.0133</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3375</td>\n",
       "      <td>-0.0039</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0216</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.5162</td>\n",
       "      <td>-0.6538</td>\n",
       "      <td>-0.4945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.402</td>\n",
       "      <td>-0.0129</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0837</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0199</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-0.5292</td>\n",
       "      <td>-0.6538</td>\n",
       "      <td>-0.4945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.402</td>\n",
       "      <td>-0.0129</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   delta_t    acc0    acc1    acc2   gyro0   gyro1   gyro2    mag0    mag1  \\\n",
       "0   0.0000 -0.0029  0.0003 -0.0003 -0.0194  0.0124 -0.0022 -0.5292 -0.6538   \n",
       "1   0.0891 -0.0029  0.0013  0.0007 -0.0085  0.0023  0.0006 -0.5292 -0.6538   \n",
       "2   0.0810 -0.0039  0.0013 -0.0003 -0.0199  0.0086 -0.0024 -0.5162 -0.6538   \n",
       "3   0.3375 -0.0039  0.0013  0.0007 -0.0216  0.0054 -0.0002 -0.5162 -0.6538   \n",
       "4   0.0837 -0.0029  0.0023  0.0007 -0.0199  0.0171  0.0005 -0.5292 -0.6538   \n",
       "\n",
       "     mag2   ...         y      z    beta     Qx     Qy     Qz   Qw  delta_x  \\\n",
       "0 -0.5275   ...     0.221  0.402 -0.0129  0.005  0.020  0.000  1.0      0.0   \n",
       "1 -0.4945   ...     0.221  0.402 -0.0128  0.005  0.020  0.001  1.0      0.0   \n",
       "2 -0.5275   ...     0.221  0.402 -0.0133  0.005  0.021  0.000  1.0      0.0   \n",
       "3 -0.4945   ...     0.221  0.402 -0.0129  0.005  0.020  0.000  1.0      0.0   \n",
       "4 -0.4945   ...     0.221  0.402 -0.0129  0.005  0.020  0.000  1.0      0.0   \n",
       "\n",
       "   delta_y  delta_z  \n",
       "0      0.0      0.0  \n",
       "1      0.0      0.0  \n",
       "2      0.0      0.0  \n",
       "3      0.0      0.0  \n",
       "4      0.0      0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6142\n"
     ]
    }
   ],
   "source": [
    "split = round(df.shape[0]*0.8)\n",
    "print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6142, 1, 10) (6142,) (1536, 1, 10) (1536,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = df.values\n",
    "train = values[:split, :]\n",
    "test = values[split:, :]\n",
    "# split into input and outputs\n",
    "\n",
    "#here comes the horizontal separation\n",
    "train_X, train_y = train[:, :-11], train[:, -8]\n",
    "test_X, test_y = test[:, :-11], test[:, -8]\n",
    "\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "patience=40\n",
    "early_stopping=EarlyStopping(monitor = 'val_loss', patience=patience, verbose=1)\n",
    "checkpointer=ModelCheckpoint(filepath=\"LSTM_beta_weights.hdf5\", save_best_only=True, verbose =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for Beta (orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6142 samples, validate on 1536 samples\n",
      "Epoch 1/500\n",
      " - 4s - loss: 0.4283 - val_loss: 0.2407\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24072, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 2/500\n",
      " - 1s - loss: 0.2795 - val_loss: 0.1643\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24072 to 0.16432, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 3/500\n",
      " - 0s - loss: 0.2118 - val_loss: 0.1764\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16432\n",
      "Epoch 4/500\n",
      " - 1s - loss: 0.2115 - val_loss: 0.1707\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16432\n",
      "Epoch 5/500\n",
      " - 1s - loss: 0.2096 - val_loss: 0.1673\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16432\n",
      "Epoch 6/500\n",
      " - 0s - loss: 0.2073 - val_loss: 0.1641\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.16432 to 0.16405, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 7/500\n",
      " - 0s - loss: 0.2052 - val_loss: 0.1610\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.16405 to 0.16098, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 8/500\n",
      " - 1s - loss: 0.2033 - val_loss: 0.1582\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.16098 to 0.15823, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 9/500\n",
      " - 1s - loss: 0.2012 - val_loss: 0.1555\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.15823 to 0.15551, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 10/500\n",
      " - 0s - loss: 0.1992 - val_loss: 0.1527\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.15551 to 0.15272, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 11/500\n",
      " - 1s - loss: 0.1972 - val_loss: 0.1502\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.15272 to 0.15017, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 12/500\n",
      " - 0s - loss: 0.1951 - val_loss: 0.1475\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.15017 to 0.14750, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 13/500\n",
      " - 0s - loss: 0.1932 - val_loss: 0.1446\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.14750 to 0.14458, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 14/500\n",
      " - 0s - loss: 0.1910 - val_loss: 0.1416\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.14458 to 0.14155, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 15/500\n",
      " - 0s - loss: 0.1886 - val_loss: 0.1380\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.14155 to 0.13797, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 16/500\n",
      " - 0s - loss: 0.1865 - val_loss: 0.1351\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.13797 to 0.13511, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 17/500\n",
      " - 0s - loss: 0.1844 - val_loss: 0.1308\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.13511 to 0.13077, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 18/500\n",
      " - 1s - loss: 0.1821 - val_loss: 0.1271\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.13077 to 0.12712, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 19/500\n",
      " - 0s - loss: 0.1802 - val_loss: 0.1237\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.12712 to 0.12374, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 20/500\n",
      " - 0s - loss: 0.1784 - val_loss: 0.1202\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.12374 to 0.12021, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 21/500\n",
      " - 0s - loss: 0.1767 - val_loss: 0.1174\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.12021 to 0.11745, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 22/500\n",
      " - 0s - loss: 0.1751 - val_loss: 0.1157\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.11745 to 0.11567, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 23/500\n",
      " - 0s - loss: 0.1740 - val_loss: 0.1151\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.11567 to 0.11514, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 24/500\n",
      " - 0s - loss: 0.1732 - val_loss: 0.1147\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.11514 to 0.11471, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 25/500\n",
      " - 0s - loss: 0.1726 - val_loss: 0.1146\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.11471 to 0.11456, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 26/500\n",
      " - 0s - loss: 0.1720 - val_loss: 0.1147\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.11456\n",
      "Epoch 27/500\n",
      " - 0s - loss: 0.1715 - val_loss: 0.1145\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.11456 to 0.11446, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 28/500\n",
      " - 0s - loss: 0.1712 - val_loss: 0.1143\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.11446 to 0.11430, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 29/500\n",
      " - 0s - loss: 0.1709 - val_loss: 0.1137\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.11430 to 0.11369, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 30/500\n",
      " - 0s - loss: 0.1706 - val_loss: 0.1136\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.11369 to 0.11356, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 31/500\n",
      " - 0s - loss: 0.1703 - val_loss: 0.1134\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.11356 to 0.11341, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 32/500\n",
      " - 0s - loss: 0.1700 - val_loss: 0.1134\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.11341 to 0.11336, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 33/500\n",
      " - 0s - loss: 0.1698 - val_loss: 0.1129\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.11336 to 0.11287, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 34/500\n",
      " - 0s - loss: 0.1696 - val_loss: 0.1129\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.11287 to 0.11286, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 35/500\n",
      " - 0s - loss: 0.1693 - val_loss: 0.1125\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.11286 to 0.11248, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 36/500\n",
      " - 0s - loss: 0.1691 - val_loss: 0.1123\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.11248 to 0.11230, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 37/500\n",
      " - 0s - loss: 0.1690 - val_loss: 0.1120\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.11230 to 0.11198, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 38/500\n",
      " - 0s - loss: 0.1688 - val_loss: 0.1117\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.11198 to 0.11169, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 39/500\n",
      " - 0s - loss: 0.1686 - val_loss: 0.1116\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.11169 to 0.11160, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 40/500\n",
      " - 0s - loss: 0.1684 - val_loss: 0.1113\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.11160 to 0.11132, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 41/500\n",
      " - 0s - loss: 0.1683 - val_loss: 0.1110\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.11132 to 0.11101, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 42/500\n",
      " - 0s - loss: 0.1681 - val_loss: 0.1108\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.11101 to 0.11078, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 43/500\n",
      " - 1s - loss: 0.1679 - val_loss: 0.1106\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.11078 to 0.11062, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 44/500\n",
      " - 0s - loss: 0.1677 - val_loss: 0.1106\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.11062 to 0.11057, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 45/500\n",
      " - 0s - loss: 0.1675 - val_loss: 0.1104\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.11057 to 0.11042, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 46/500\n",
      " - 0s - loss: 0.1674 - val_loss: 0.1102\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.11042 to 0.11024, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 47/500\n",
      " - 0s - loss: 0.1672 - val_loss: 0.1101\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.11024 to 0.11009, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 48/500\n",
      " - 0s - loss: 0.1671 - val_loss: 0.1099\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.11009 to 0.10990, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 49/500\n",
      " - 0s - loss: 0.1669 - val_loss: 0.1097\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.10990 to 0.10970, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 50/500\n",
      " - 0s - loss: 0.1668 - val_loss: 0.1096\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.10970 to 0.10961, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 51/500\n",
      " - 1s - loss: 0.1666 - val_loss: 0.1094\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.10961 to 0.10941, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 52/500\n",
      " - 0s - loss: 0.1664 - val_loss: 0.1093\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.10941 to 0.10930, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 53/500\n",
      " - 0s - loss: 0.1663 - val_loss: 0.1090\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.10930 to 0.10902, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 54/500\n",
      " - 0s - loss: 0.1660 - val_loss: 0.1090\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.10902 to 0.10897, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 55/500\n",
      " - 0s - loss: 0.1659 - val_loss: 0.1086\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.10897 to 0.10860, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 56/500\n",
      " - 0s - loss: 0.1658 - val_loss: 0.1086\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.10860\n",
      "Epoch 57/500\n",
      " - 0s - loss: 0.1656 - val_loss: 0.1084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00057: val_loss improved from 0.10860 to 0.10838, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 58/500\n",
      " - 0s - loss: 0.1654 - val_loss: 0.1084\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.10838 to 0.10836, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 59/500\n",
      " - 0s - loss: 0.1652 - val_loss: 0.1082\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.10836 to 0.10820, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 60/500\n",
      " - 1s - loss: 0.1651 - val_loss: 0.1080\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.10820 to 0.10799, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 61/500\n",
      " - 0s - loss: 0.1649 - val_loss: 0.1079\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.10799 to 0.10794, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 62/500\n",
      " - 0s - loss: 0.1648 - val_loss: 0.1078\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.10794 to 0.10779, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 63/500\n",
      " - 1s - loss: 0.1647 - val_loss: 0.1076\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.10779 to 0.10760, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 64/500\n",
      " - 0s - loss: 0.1644 - val_loss: 0.1074\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.10760 to 0.10743, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 65/500\n",
      " - 0s - loss: 0.1643 - val_loss: 0.1073\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.10743 to 0.10733, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 66/500\n",
      " - 0s - loss: 0.1641 - val_loss: 0.1072\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.10733 to 0.10724, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 67/500\n",
      " - 0s - loss: 0.1640 - val_loss: 0.1071\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.10724 to 0.10710, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 68/500\n",
      " - 0s - loss: 0.1638 - val_loss: 0.1069\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.10710 to 0.10693, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 69/500\n",
      " - 0s - loss: 0.1636 - val_loss: 0.1069\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.10693 to 0.10685, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 70/500\n",
      " - 0s - loss: 0.1634 - val_loss: 0.1067\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.10685 to 0.10666, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 71/500\n",
      " - 1s - loss: 0.1632 - val_loss: 0.1066\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.10666 to 0.10659, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 72/500\n",
      " - 0s - loss: 0.1630 - val_loss: 0.1064\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.10659 to 0.10644, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 73/500\n",
      " - 0s - loss: 0.1628 - val_loss: 0.1064\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.10644 to 0.10635, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 74/500\n",
      " - 0s - loss: 0.1627 - val_loss: 0.1062\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.10635 to 0.10623, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 75/500\n",
      " - 0s - loss: 0.1624 - val_loss: 0.1061\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.10623 to 0.10613, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 76/500\n",
      " - 0s - loss: 0.1622 - val_loss: 0.1060\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.10613 to 0.10604, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 77/500\n",
      " - 0s - loss: 0.1620 - val_loss: 0.1059\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.10604 to 0.10592, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 78/500\n",
      " - 0s - loss: 0.1619 - val_loss: 0.1058\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.10592 to 0.10584, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 79/500\n",
      " - 0s - loss: 0.1616 - val_loss: 0.1055\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.10584 to 0.10554, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 80/500\n",
      " - 0s - loss: 0.1614 - val_loss: 0.1054\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.10554 to 0.10541, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 81/500\n",
      " - 0s - loss: 0.1612 - val_loss: 0.1053\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.10541 to 0.10526, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 82/500\n",
      " - 0s - loss: 0.1610 - val_loss: 0.1051\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.10526 to 0.10514, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 83/500\n",
      " - 0s - loss: 0.1609 - val_loss: 0.1050\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.10514 to 0.10496, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 84/500\n",
      " - 0s - loss: 0.1607 - val_loss: 0.1048\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.10496 to 0.10481, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 85/500\n",
      " - 0s - loss: 0.1605 - val_loss: 0.1047\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.10481 to 0.10465, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 86/500\n",
      " - 0s - loss: 0.1602 - val_loss: 0.1044\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.10465 to 0.10443, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 87/500\n",
      " - 1s - loss: 0.1600 - val_loss: 0.1043\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.10443 to 0.10430, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 88/500\n",
      " - 0s - loss: 0.1599 - val_loss: 0.1041\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.10430 to 0.10412, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 89/500\n",
      " - 0s - loss: 0.1597 - val_loss: 0.1041\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.10412 to 0.10405, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 90/500\n",
      " - 0s - loss: 0.1594 - val_loss: 0.1038\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.10405 to 0.10380, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 91/500\n",
      " - 0s - loss: 0.1592 - val_loss: 0.1036\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.10380 to 0.10356, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 92/500\n",
      " - 0s - loss: 0.1590 - val_loss: 0.1033\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.10356 to 0.10333, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 93/500\n",
      " - 0s - loss: 0.1588 - val_loss: 0.1031\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.10333 to 0.10311, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 94/500\n",
      " - 0s - loss: 0.1586 - val_loss: 0.1029\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.10311 to 0.10294, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 95/500\n",
      " - 1s - loss: 0.1584 - val_loss: 0.1027\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.10294 to 0.10270, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 96/500\n",
      " - 0s - loss: 0.1582 - val_loss: 0.1025\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.10270 to 0.10247, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 97/500\n",
      " - 0s - loss: 0.1580 - val_loss: 0.1022\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.10247 to 0.10225, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 98/500\n",
      " - 0s - loss: 0.1578 - val_loss: 0.1021\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.10225 to 0.10209, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 99/500\n",
      " - 0s - loss: 0.1576 - val_loss: 0.1021\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.10209 to 0.10207, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 100/500\n",
      " - 0s - loss: 0.1573 - val_loss: 0.1019\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.10207 to 0.10188, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 101/500\n",
      " - 0s - loss: 0.1571 - val_loss: 0.1018\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.10188 to 0.10184, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 102/500\n",
      " - 0s - loss: 0.1568 - val_loss: 0.1017\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.10184 to 0.10167, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 103/500\n",
      " - 1s - loss: 0.1565 - val_loss: 0.1014\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.10167 to 0.10140, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 104/500\n",
      " - 0s - loss: 0.1563 - val_loss: 0.1012\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.10140 to 0.10124, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 105/500\n",
      " - 0s - loss: 0.1561 - val_loss: 0.1011\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.10124 to 0.10115, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 106/500\n",
      " - 0s - loss: 0.1558 - val_loss: 0.1010\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.10115 to 0.10102, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 107/500\n",
      " - 0s - loss: 0.1555 - val_loss: 0.1007\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.10102 to 0.10069, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 108/500\n",
      " - 0s - loss: 0.1553 - val_loss: 0.1006\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.10069 to 0.10061, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 109/500\n",
      " - 0s - loss: 0.1550 - val_loss: 0.1004\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.10061 to 0.10035, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 110/500\n",
      " - 1s - loss: 0.1547 - val_loss: 0.1000\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.10035 to 0.10003, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 111/500\n",
      " - 0s - loss: 0.1545 - val_loss: 0.1000\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.10003 to 0.09996, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 112/500\n",
      " - 0s - loss: 0.1542 - val_loss: 0.0995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00112: val_loss improved from 0.09996 to 0.09947, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 113/500\n",
      " - 0s - loss: 0.1539 - val_loss: 0.0993\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.09947 to 0.09931, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 114/500\n",
      " - 1s - loss: 0.1536 - val_loss: 0.0990\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.09931 to 0.09899, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 115/500\n",
      " - 0s - loss: 0.1533 - val_loss: 0.0988\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.09899 to 0.09880, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 116/500\n",
      " - 0s - loss: 0.1530 - val_loss: 0.0987\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.09880 to 0.09866, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 117/500\n",
      " - 0s - loss: 0.1527 - val_loss: 0.0984\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.09866 to 0.09836, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 118/500\n",
      " - 0s - loss: 0.1525 - val_loss: 0.0982\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.09836 to 0.09821, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 119/500\n",
      " - 0s - loss: 0.1521 - val_loss: 0.0979\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.09821 to 0.09792, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 120/500\n",
      " - 0s - loss: 0.1519 - val_loss: 0.0977\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.09792 to 0.09773, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 121/500\n",
      " - 0s - loss: 0.1515 - val_loss: 0.0974\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.09773 to 0.09742, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 122/500\n",
      " - 0s - loss: 0.1512 - val_loss: 0.0971\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.09742 to 0.09709, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 123/500\n",
      " - 0s - loss: 0.1509 - val_loss: 0.0970\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.09709 to 0.09702, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 124/500\n",
      " - 0s - loss: 0.1506 - val_loss: 0.0968\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.09702 to 0.09676, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 125/500\n",
      " - 0s - loss: 0.1504 - val_loss: 0.0967\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.09676 to 0.09665, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 126/500\n",
      " - 0s - loss: 0.1501 - val_loss: 0.0966\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.09665 to 0.09662, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 127/500\n",
      " - 0s - loss: 0.1498 - val_loss: 0.0963\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.09662 to 0.09634, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 128/500\n",
      " - 0s - loss: 0.1496 - val_loss: 0.0964\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.09634\n",
      "Epoch 129/500\n",
      " - 0s - loss: 0.1492 - val_loss: 0.0961\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.09634 to 0.09610, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 130/500\n",
      " - 1s - loss: 0.1490 - val_loss: 0.0960\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.09610 to 0.09597, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 131/500\n",
      " - 0s - loss: 0.1488 - val_loss: 0.0958\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.09597 to 0.09584, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 132/500\n",
      " - 0s - loss: 0.1486 - val_loss: 0.0957\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.09584 to 0.09571, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 133/500\n",
      " - 1s - loss: 0.1482 - val_loss: 0.0955\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.09571 to 0.09547, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 134/500\n",
      " - 1s - loss: 0.1480 - val_loss: 0.0954\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.09547 to 0.09538, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 135/500\n",
      " - 0s - loss: 0.1477 - val_loss: 0.0953\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.09538 to 0.09533, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 136/500\n",
      " - 0s - loss: 0.1475 - val_loss: 0.0952\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.09533 to 0.09519, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 137/500\n",
      " - 0s - loss: 0.1471 - val_loss: 0.0951\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.09519 to 0.09508, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 138/500\n",
      " - 1s - loss: 0.1469 - val_loss: 0.0950\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.09508 to 0.09496, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 139/500\n",
      " - 0s - loss: 0.1466 - val_loss: 0.0949\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.09496 to 0.09485, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 140/500\n",
      " - 0s - loss: 0.1463 - val_loss: 0.0946\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.09485 to 0.09458, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 141/500\n",
      " - 0s - loss: 0.1461 - val_loss: 0.0946\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.09458 to 0.09455, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 142/500\n",
      " - 1s - loss: 0.1458 - val_loss: 0.0943\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.09455 to 0.09430, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 143/500\n",
      " - 0s - loss: 0.1456 - val_loss: 0.0942\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.09430 to 0.09420, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 144/500\n",
      " - 0s - loss: 0.1452 - val_loss: 0.0940\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.09420 to 0.09396, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 145/500\n",
      " - 0s - loss: 0.1449 - val_loss: 0.0939\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.09396 to 0.09392, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 146/500\n",
      " - 1s - loss: 0.1447 - val_loss: 0.0938\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.09392 to 0.09385, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 147/500\n",
      " - 0s - loss: 0.1444 - val_loss: 0.0937\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.09385 to 0.09369, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 148/500\n",
      " - 0s - loss: 0.1442 - val_loss: 0.0936\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.09369 to 0.09365, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 149/500\n",
      " - 0s - loss: 0.1439 - val_loss: 0.0935\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.09365 to 0.09353, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 150/500\n",
      " - 0s - loss: 0.1437 - val_loss: 0.0933\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.09353 to 0.09331, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 151/500\n",
      " - 0s - loss: 0.1434 - val_loss: 0.0933\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.09331\n",
      "Epoch 152/500\n",
      " - 0s - loss: 0.1432 - val_loss: 0.0931\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.09331 to 0.09314, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 153/500\n",
      " - 0s - loss: 0.1431 - val_loss: 0.0930\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.09314 to 0.09304, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 154/500\n",
      " - 0s - loss: 0.1428 - val_loss: 0.0929\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.09304 to 0.09293, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 155/500\n",
      " - 0s - loss: 0.1427 - val_loss: 0.0929\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.09293 to 0.09287, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 156/500\n",
      " - 0s - loss: 0.1425 - val_loss: 0.0929\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.09287 to 0.09285, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 157/500\n",
      " - 0s - loss: 0.1423 - val_loss: 0.0927\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.09285 to 0.09268, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 158/500\n",
      " - 0s - loss: 0.1422 - val_loss: 0.0927\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.09268\n",
      "Epoch 159/500\n",
      " - 0s - loss: 0.1419 - val_loss: 0.0926\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.09268 to 0.09257, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 160/500\n",
      " - 0s - loss: 0.1417 - val_loss: 0.0925\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.09257 to 0.09254, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 161/500\n",
      " - 0s - loss: 0.1415 - val_loss: 0.0923\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.09254 to 0.09231, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 162/500\n",
      " - 0s - loss: 0.1412 - val_loss: 0.0922\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.09231 to 0.09220, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 163/500\n",
      " - 0s - loss: 0.1411 - val_loss: 0.0921\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.09220 to 0.09214, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 164/500\n",
      " - 0s - loss: 0.1409 - val_loss: 0.0919\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.09214 to 0.09193, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 165/500\n",
      " - 0s - loss: 0.1407 - val_loss: 0.0918\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.09193 to 0.09180, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 166/500\n",
      " - 0s - loss: 0.1405 - val_loss: 0.0919\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.09180\n",
      "Epoch 167/500\n",
      " - 0s - loss: 0.1404 - val_loss: 0.0917\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.09180 to 0.09167, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 168/500\n",
      " - 0s - loss: 0.1402 - val_loss: 0.0916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00168: val_loss improved from 0.09167 to 0.09159, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 169/500\n",
      " - 1s - loss: 0.1399 - val_loss: 0.0914\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.09159 to 0.09143, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 170/500\n",
      " - 0s - loss: 0.1398 - val_loss: 0.0915\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.09143\n",
      "Epoch 171/500\n",
      " - 0s - loss: 0.1397 - val_loss: 0.0913\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.09143 to 0.09134, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 172/500\n",
      " - 0s - loss: 0.1395 - val_loss: 0.0913\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.09134 to 0.09126, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 173/500\n",
      " - 0s - loss: 0.1394 - val_loss: 0.0912\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.09126 to 0.09117, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 174/500\n",
      " - 0s - loss: 0.1392 - val_loss: 0.0911\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.09117 to 0.09108, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 175/500\n",
      " - 0s - loss: 0.1390 - val_loss: 0.0908\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.09108 to 0.09084, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 176/500\n",
      " - 0s - loss: 0.1389 - val_loss: 0.0909\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.09084\n",
      "Epoch 177/500\n",
      " - 1s - loss: 0.1387 - val_loss: 0.0906\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.09084 to 0.09062, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 178/500\n",
      " - 0s - loss: 0.1385 - val_loss: 0.0905\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.09062 to 0.09051, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 179/500\n",
      " - 0s - loss: 0.1384 - val_loss: 0.0904\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.09051 to 0.09039, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 180/500\n",
      " - 0s - loss: 0.1383 - val_loss: 0.0905\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.09039\n",
      "Epoch 181/500\n",
      " - 0s - loss: 0.1381 - val_loss: 0.0904\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.09039\n",
      "Epoch 182/500\n",
      " - 0s - loss: 0.1379 - val_loss: 0.0903\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.09039 to 0.09035, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 183/500\n",
      " - 0s - loss: 0.1378 - val_loss: 0.0901\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.09035 to 0.09014, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 184/500\n",
      " - 0s - loss: 0.1376 - val_loss: 0.0902\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.09014\n",
      "Epoch 185/500\n",
      " - 0s - loss: 0.1374 - val_loss: 0.0899\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.09014 to 0.08987, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 186/500\n",
      " - 0s - loss: 0.1373 - val_loss: 0.0897\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.08987 to 0.08973, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 187/500\n",
      " - 0s - loss: 0.1371 - val_loss: 0.0898\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.08973\n",
      "Epoch 188/500\n",
      " - 0s - loss: 0.1370 - val_loss: 0.0897\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.08973 to 0.08969, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 189/500\n",
      " - 0s - loss: 0.1368 - val_loss: 0.0895\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.08969 to 0.08949, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 190/500\n",
      " - 0s - loss: 0.1367 - val_loss: 0.0895\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.08949\n",
      "Epoch 191/500\n",
      " - 0s - loss: 0.1365 - val_loss: 0.0894\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.08949 to 0.08937, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 192/500\n",
      " - 0s - loss: 0.1364 - val_loss: 0.0893\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.08937 to 0.08933, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 193/500\n",
      " - 0s - loss: 0.1363 - val_loss: 0.0892\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.08933 to 0.08919, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 194/500\n",
      " - 0s - loss: 0.1362 - val_loss: 0.0890\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.08919 to 0.08903, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 195/500\n",
      " - 0s - loss: 0.1361 - val_loss: 0.0889\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.08903 to 0.08891, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 196/500\n",
      " - 0s - loss: 0.1360 - val_loss: 0.0888\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.08891 to 0.08885, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 197/500\n",
      " - 0s - loss: 0.1359 - val_loss: 0.0888\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.08885 to 0.08882, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 198/500\n",
      " - 0s - loss: 0.1357 - val_loss: 0.0887\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.08882 to 0.08868, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 199/500\n",
      " - 0s - loss: 0.1356 - val_loss: 0.0887\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.08868 to 0.08866, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 200/500\n",
      " - 0s - loss: 0.1355 - val_loss: 0.0885\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.08866 to 0.08852, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 201/500\n",
      " - 0s - loss: 0.1353 - val_loss: 0.0885\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.08852 to 0.08848, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 202/500\n",
      " - 0s - loss: 0.1352 - val_loss: 0.0884\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.08848 to 0.08842, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 203/500\n",
      " - 0s - loss: 0.1351 - val_loss: 0.0884\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.08842 to 0.08836, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 204/500\n",
      " - 0s - loss: 0.1349 - val_loss: 0.0883\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.08836 to 0.08827, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 205/500\n",
      " - 0s - loss: 0.1348 - val_loss: 0.0882\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.08827 to 0.08823, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 206/500\n",
      " - 0s - loss: 0.1347 - val_loss: 0.0880\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.08823 to 0.08798, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 207/500\n",
      " - 0s - loss: 0.1345 - val_loss: 0.0879\n",
      "\n",
      "Epoch 00207: val_loss improved from 0.08798 to 0.08794, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 208/500\n",
      " - 0s - loss: 0.1345 - val_loss: 0.0878\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.08794 to 0.08781, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 209/500\n",
      " - 1s - loss: 0.1343 - val_loss: 0.0876\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.08781 to 0.08763, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 210/500\n",
      " - 0s - loss: 0.1342 - val_loss: 0.0876\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.08763 to 0.08759, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 211/500\n",
      " - 0s - loss: 0.1340 - val_loss: 0.0874\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.08759 to 0.08737, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 212/500\n",
      " - 0s - loss: 0.1340 - val_loss: 0.0874\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.08737\n",
      "Epoch 213/500\n",
      " - 1s - loss: 0.1338 - val_loss: 0.0871\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.08737 to 0.08715, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 214/500\n",
      " - 0s - loss: 0.1336 - val_loss: 0.0870\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.08715 to 0.08699, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 215/500\n",
      " - 0s - loss: 0.1335 - val_loss: 0.0871\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.08699\n",
      "Epoch 216/500\n",
      " - 0s - loss: 0.1334 - val_loss: 0.0869\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.08699 to 0.08693, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 217/500\n",
      " - 1s - loss: 0.1333 - val_loss: 0.0868\n",
      "\n",
      "Epoch 00217: val_loss improved from 0.08693 to 0.08676, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 218/500\n",
      " - 0s - loss: 0.1332 - val_loss: 0.0867\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.08676 to 0.08669, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 219/500\n",
      " - 0s - loss: 0.1330 - val_loss: 0.0866\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.08669 to 0.08665, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 220/500\n",
      " - 0s - loss: 0.1329 - val_loss: 0.0866\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.08665 to 0.08662, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 221/500\n",
      " - 0s - loss: 0.1327 - val_loss: 0.0866\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.08662 to 0.08656, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 222/500\n",
      " - 0s - loss: 0.1326 - val_loss: 0.0865\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.08656 to 0.08648, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 223/500\n",
      " - 0s - loss: 0.1325 - val_loss: 0.0863\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.08648 to 0.08634, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 224/500\n",
      " - 0s - loss: 0.1323 - val_loss: 0.0863\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.08634 to 0.08631, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 225/500\n",
      " - 0s - loss: 0.1322 - val_loss: 0.0861\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.08631 to 0.08608, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 226/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1320 - val_loss: 0.0861\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.08608 to 0.08605, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 227/500\n",
      " - 0s - loss: 0.1319 - val_loss: 0.0859\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.08605 to 0.08594, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 228/500\n",
      " - 0s - loss: 0.1317 - val_loss: 0.0860\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.08594\n",
      "Epoch 229/500\n",
      " - 1s - loss: 0.1316 - val_loss: 0.0858\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.08594 to 0.08582, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 230/500\n",
      " - 0s - loss: 0.1315 - val_loss: 0.0858\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.08582\n",
      "Epoch 231/500\n",
      " - 0s - loss: 0.1314 - val_loss: 0.0857\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.08582 to 0.08572, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 232/500\n",
      " - 0s - loss: 0.1313 - val_loss: 0.0857\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.08572 to 0.08569, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 233/500\n",
      " - 0s - loss: 0.1311 - val_loss: 0.0855\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.08569 to 0.08551, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 234/500\n",
      " - 0s - loss: 0.1309 - val_loss: 0.0854\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.08551 to 0.08540, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 235/500\n",
      " - 0s - loss: 0.1308 - val_loss: 0.0853\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.08540 to 0.08528, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 236/500\n",
      " - 0s - loss: 0.1306 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.08528 to 0.08523, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 237/500\n",
      " - 0s - loss: 0.1306 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.08523\n",
      "Epoch 238/500\n",
      " - 0s - loss: 0.1304 - val_loss: 0.0851\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.08523 to 0.08508, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 239/500\n",
      " - 0s - loss: 0.1303 - val_loss: 0.0851\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.08508\n",
      "Epoch 240/500\n",
      " - 0s - loss: 0.1302 - val_loss: 0.0850\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.08508 to 0.08496, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 241/500\n",
      " - 1s - loss: 0.1301 - val_loss: 0.0850\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.08496\n",
      "Epoch 242/500\n",
      " - 1s - loss: 0.1299 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.08496 to 0.08478, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 243/500\n",
      " - 0s - loss: 0.1298 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.08478 to 0.08474, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 244/500\n",
      " - 0s - loss: 0.1297 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.08474\n",
      "Epoch 245/500\n",
      " - 1s - loss: 0.1295 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.08474\n",
      "Epoch 246/500\n",
      " - 1s - loss: 0.1294 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.08474 to 0.08474, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 247/500\n",
      " - 0s - loss: 0.1293 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00247: val_loss improved from 0.08474 to 0.08468, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 248/500\n",
      " - 1s - loss: 0.1291 - val_loss: 0.0846\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.08468 to 0.08465, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 249/500\n",
      " - 1s - loss: 0.1290 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.08465 to 0.08453, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 250/500\n",
      " - 1s - loss: 0.1289 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00250: val_loss improved from 0.08453 to 0.08450, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 251/500\n",
      " - 1s - loss: 0.1288 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00251: val_loss improved from 0.08450 to 0.08448, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 252/500\n",
      " - 1s - loss: 0.1286 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00252: val_loss improved from 0.08448 to 0.08438, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 253/500\n",
      " - 1s - loss: 0.1285 - val_loss: 0.0843\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.08438 to 0.08432, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 254/500\n",
      " - 1s - loss: 0.1284 - val_loss: 0.0843\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.08432 to 0.08431, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 255/500\n",
      " - 1s - loss: 0.1283 - val_loss: 0.0842\n",
      "\n",
      "Epoch 00255: val_loss improved from 0.08431 to 0.08418, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 256/500\n",
      " - 1s - loss: 0.1282 - val_loss: 0.0842\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.08418\n",
      "Epoch 257/500\n",
      " - 1s - loss: 0.1280 - val_loss: 0.0842\n",
      "\n",
      "Epoch 00257: val_loss improved from 0.08418 to 0.08418, saving model to LSTM_beta_weights.hdf5\n",
      "Epoch 258/500\n",
      " - 0s - loss: 0.1279 - val_loss: 0.0842\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.08418\n",
      "Epoch 259/500\n",
      " - 0s - loss: 0.1278 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.08418\n",
      "Epoch 260/500\n",
      " - 0s - loss: 0.1277 - val_loss: 0.0842\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.08418\n",
      "Epoch 261/500\n",
      " - 0s - loss: 0.1276 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.08418\n",
      "Epoch 262/500\n",
      " - 0s - loss: 0.1275 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.08418\n",
      "Epoch 263/500\n",
      " - 0s - loss: 0.1273 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.08418\n",
      "Epoch 264/500\n",
      " - 0s - loss: 0.1272 - val_loss: 0.0843\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.08418\n",
      "Epoch 265/500\n",
      " - 0s - loss: 0.1271 - val_loss: 0.0843\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.08418\n",
      "Epoch 266/500\n",
      " - 0s - loss: 0.1270 - val_loss: 0.0843\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.08418\n",
      "Epoch 267/500\n",
      " - 0s - loss: 0.1268 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.08418\n",
      "Epoch 268/500\n",
      " - 0s - loss: 0.1268 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.08418\n",
      "Epoch 269/500\n",
      " - 0s - loss: 0.1266 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.08418\n",
      "Epoch 270/500\n",
      " - 0s - loss: 0.1265 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.08418\n",
      "Epoch 271/500\n",
      " - 0s - loss: 0.1264 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.08418\n",
      "Epoch 272/500\n",
      " - 0s - loss: 0.1263 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.08418\n",
      "Epoch 273/500\n",
      " - 0s - loss: 0.1262 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.08418\n",
      "Epoch 274/500\n",
      " - 0s - loss: 0.1261 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.08418\n",
      "Epoch 275/500\n",
      " - 0s - loss: 0.1259 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.08418\n",
      "Epoch 276/500\n",
      " - 0s - loss: 0.1259 - val_loss: 0.0846\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.08418\n",
      "Epoch 277/500\n",
      " - 0s - loss: 0.1258 - val_loss: 0.0846\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.08418\n",
      "Epoch 278/500\n",
      " - 0s - loss: 0.1256 - val_loss: 0.0846\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.08418\n",
      "Epoch 279/500\n",
      " - 0s - loss: 0.1255 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.08418\n",
      "Epoch 280/500\n",
      " - 0s - loss: 0.1254 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.08418\n",
      "Epoch 281/500\n",
      " - 0s - loss: 0.1253 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.08418\n",
      "Epoch 282/500\n",
      " - 0s - loss: 0.1252 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.08418\n",
      "Epoch 283/500\n",
      " - 0s - loss: 0.1251 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.08418\n",
      "Epoch 284/500\n",
      " - 0s - loss: 0.1250 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.08418\n",
      "Epoch 285/500\n",
      " - 0s - loss: 0.1250 - val_loss: 0.0850\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.08418\n",
      "Epoch 286/500\n",
      " - 0s - loss: 0.1248 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.08418\n",
      "Epoch 287/500\n",
      " - 0s - loss: 0.1247 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.08418\n",
      "Epoch 288/500\n",
      " - 0s - loss: 0.1246 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.08418\n",
      "Epoch 289/500\n",
      " - 0s - loss: 0.1245 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.08418\n",
      "Epoch 290/500\n",
      " - 0s - loss: 0.1243 - val_loss: 0.0850\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.08418\n",
      "Epoch 291/500\n",
      " - 0s - loss: 0.1242 - val_loss: 0.0851\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.08418\n",
      "Epoch 292/500\n",
      " - 0s - loss: 0.1241 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.08418\n",
      "Epoch 293/500\n",
      " - 0s - loss: 0.1240 - val_loss: 0.0853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00293: val_loss did not improve from 0.08418\n",
      "Epoch 294/500\n",
      " - 0s - loss: 0.1239 - val_loss: 0.0853\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.08418\n",
      "Epoch 295/500\n",
      " - 0s - loss: 0.1238 - val_loss: 0.0854\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.08418\n",
      "Epoch 296/500\n",
      " - 0s - loss: 0.1237 - val_loss: 0.0855\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.08418\n",
      "Epoch 297/500\n",
      " - 0s - loss: 0.1236 - val_loss: 0.0855\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.08418\n",
      "Epoch 00297: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=500, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks = [checkpointer,early_stopping])\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.185\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(test_y, yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
