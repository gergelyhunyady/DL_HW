{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os   # For path operations\n",
    "import datetime\n",
    "\n",
    "import hyperas\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config GPU env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17666100762923520416\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3168377241\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2251382907064936133\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "# Device check\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Def NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience=40\n",
    "early_stopping=EarlyStopping(monitor = 'val_loss', patience=patience, verbose=1)\n",
    "checkpointer=ModelCheckpoint(filepath=\"CNN_weights_dxyz.hdf5\", save_best_only=True, verbose =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a 1D convnet based on the practice lesson for time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_1d_convnet(window_size, filter_length, nb_input_series=1, nb_outputs=1,nb_filter=4):\n",
    "    model = Sequential()\n",
    "    # Defining input shape of the first layer based on desired output type\n",
    "    model.add(Conv1D(filters = nb_filter, kernel_size = filter_length, activation = 'relu', \n",
    "                    input_shape = (window_size,nb_input_series)))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Conv1D(filters = nb_filter, kernel_size = filter_length, activation = 'relu'))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nb_outputs,activation = 'linear'))\n",
    "    model.compile(loss = 'mse', optimizer = 'adam', metrics = ['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input and output format from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timeseries_instances(timeseries, window_size, nb_inputs):\n",
    "    timeseries = np.asarray(timeseries)\n",
    "    assert 0 < window_size < timeseries.shape[0] , \"Out of range 0 < {} < {}\".format(window_size,timeseries.shape[0])\n",
    "    # nb_input defines the number of input time series that we use to predict outputs\n",
    "    X = np.atleast_3d(np.array([timeseries[start:start+window_size,:nb_inputs] for start in range(0,timeseries.shape[0]-window_size)]))\n",
    "    \n",
    "    # We have 3 output signal: dx, dy and dz position    \n",
    "    y = timeseries[window_size:,-3:]\n",
    "        \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network on timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalute_timeseries(timeseries, window_size, filter_length, nb_filter, epochs, batch_size):\n",
    "    if timeseries.shape[0] == 1:\n",
    "        timeseries = timeseries.T\n",
    "    nb_samples, nb_series = timeseries.shape\n",
    "    \n",
    "    # Define in and output size based on output type\n",
    "    nb_inputs = nb_series - 11 # Only 10 inputs (previous x,y,z position is an input now)\n",
    "    nb_outputs = 3\n",
    "        \n",
    "    # Initialize model\n",
    "    model= make_1d_convnet(window_size=window_size, filter_length=filter_length, nb_input_series=nb_inputs,\n",
    "                        nb_outputs=nb_outputs,nb_filter=nb_filter)\n",
    "    model.summary()\n",
    "  \n",
    "    # Fill and split the input and output variables\n",
    "    X,y = make_timeseries_instances(timeseries, window_size,nb_inputs=nb_inputs)\n",
    "  \n",
    "    test_size = int(0.3  * nb_samples)\n",
    "    valid_size = int(0.2 * nb_samples)\n",
    "    X_train, X_valid, X_test = X[:-(test_size+valid_size),:], X[-(test_size+valid_size):-test_size,:], X[-test_size:,:]\n",
    "    y_train, y_valid, y_test = y[:-(test_size+valid_size),:], y[-(test_size+valid_size):-test_size,:], y[-test_size:,:]\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train,y_train, epochs = epochs, batch_size = batch_size, validation_data = (X_valid, y_valid),\n",
    "              verbose = 2, callbacks = [checkpointer,early_stopping])\n",
    "  \n",
    "    # Load the best model for plotting\n",
    "    bestmodel = load_model(\"CNN_weights_Bazs.hdf5\")\n",
    "    preds = bestmodel.predict(X_test)\n",
    "    targets = y_test\n",
    "    \n",
    "    # Plot the results based on output type\n",
    "    # Plot predicted dx vs target dx\n",
    "    plt.figure(0)\n",
    "    plt.plot(preds[:,0],color = 'green', label = 'dx pred')\n",
    "    plt.plot(targets[:,0],color = 'red', label = 'dx targ')\n",
    "    \n",
    "    # Plot predicted dz vs target dz\n",
    "    plt.figure(1)\n",
    "    plt.plot(preds[:,2],color = 'blue', label = 'dz pred')\n",
    "    plt.plot(targets[:,2],color = 'yellow', label = 'dz targ')\n",
    "    \n",
    "    # Plot the predicted route vs original route on dx-dz plane\n",
    "    plt.figure(2)\n",
    "    plt.plot(preds[:,0],preds[:,2], label = 'dxz pred')\n",
    "    plt.plot(targets[:,0],targets[:,2], label = 'dxz targ')\n",
    "    \n",
    "    return preds, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Bazs\\\\PreprocessedData_v3.txt',\n",
    "                               sep='\\t',\n",
    "                               decimal=',')\n",
    "header = df.columns\n",
    "df_arr =np.array(df, dtype='float64')\n",
    "df =pd.DataFrame(df_arr, columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta_t</th>\n",
       "      <th>acc0</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>gyro0</th>\n",
       "      <th>gyro1</th>\n",
       "      <th>gyro2</th>\n",
       "      <th>mag0</th>\n",
       "      <th>mag1</th>\n",
       "      <th>mag2</th>\n",
       "      <th>...</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>beta</th>\n",
       "      <th>Qx</th>\n",
       "      <th>Qy</th>\n",
       "      <th>Qz</th>\n",
       "      <th>Qw</th>\n",
       "      <th>delta_x</th>\n",
       "      <th>delta_y</th>\n",
       "      <th>delta_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>-0.0022</td>\n",
       "      <td>-0.5292</td>\n",
       "      <td>-0.6538</td>\n",
       "      <td>-0.5275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.402</td>\n",
       "      <td>-0.0129</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0891</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0085</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>-0.5292</td>\n",
       "      <td>-0.6538</td>\n",
       "      <td>-0.4945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.402</td>\n",
       "      <td>-0.0128</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   delta_t    acc0    acc1    acc2   gyro0   gyro1   gyro2    mag0    mag1  \\\n",
       "0   0.0000 -0.0029  0.0003 -0.0003 -0.0194  0.0124 -0.0022 -0.5292 -0.6538   \n",
       "1   0.0891 -0.0029  0.0013  0.0007 -0.0085  0.0023  0.0006 -0.5292 -0.6538   \n",
       "\n",
       "     mag2   ...         y      z    beta     Qx    Qy     Qz   Qw  delta_x  \\\n",
       "0 -0.5275   ...     0.221  0.402 -0.0129  0.005  0.02  0.000  1.0      0.0   \n",
       "1 -0.4945   ...     0.221  0.402 -0.0128  0.005  0.02  0.001  1.0      0.0   \n",
       "\n",
       "   delta_y  delta_z  \n",
       "0      0.0      0.0  \n",
       "1      0.0      0.0  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1D convolution\n",
    "window_size = 30\n",
    "filter_length = 10\n",
    "nb_filter = 8\n",
    "\n",
    "#Train config\n",
    "epochs = 500\n",
    "batch_size = 32\n",
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for 'max_pooling1d_2/MaxPool' (op: 'MaxPool') with input shapes: [?,1,1,8].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\0_STORAGE\\Programs\\Anaconda3\\envs\\hyper\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1575\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1576\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1577\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling1d_2/MaxPool' (op: 'MaxPool') with input shapes: [?,1,1,8].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3340598c6ac5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevalute_timeseries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilter_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-fcdc93cb2566>\u001b[0m in \u001b[0;36mevalute_timeseries\u001b[1;34m(timeseries, window_size, filter_length, nb_filter, epochs, batch_size)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Initialize model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     model= make_1d_convnet(window_size=window_size, filter_length=filter_length, nb_input_series=nb_inputs,\n\u001b[1;32m---> 12\u001b[1;33m                         nb_outputs=nb_outputs,nb_filter=nb_filter)\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-69574b12e5f2>\u001b[0m in \u001b[0;36mmake_1d_convnet\u001b[1;34m(window_size, filter_length, nb_input_series, nb_outputs, nb_filter)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'linear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\0_STORAGE\\Programs\\Anaconda3\\envs\\hyper\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32mC:\\0_STORAGE\\Programs\\Anaconda3\\envs\\hyper\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;31m# Actually call the layer,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[1;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\0_STORAGE\\Programs\\Anaconda3\\envs\\hyper\\lib\\site-packages\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     44\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m                                         data_format='channels_last')\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# remove dummy last dimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\0_STORAGE\\Programs\\Anaconda3\\envs\\hyper\\lib\\site-packages\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36m_pooling_function\u001b[1;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[0;32m     81\u001b[0m                           padding, data_format):\n\u001b[0;32m     82\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[1;32m---> 83\u001b[1;33m                           padding, data_format, pool_mode='max')\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\0_STORAGE\\Programs\\Anaconda3\\envs\\hyper\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[1;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[0;32m   3878\u001b[0m         x = tf.nn.max_pool(x, pool_size, strides,\n\u001b[0;32m   3879\u001b[0m                            \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3880\u001b[1;33m                            data_format=tf_data_format)\n\u001b[0m\u001b[0;32m   3881\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'avg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3882\u001b[0m         x = tf.nn.avg_pool(x, pool_size, strides,\n",
      "\u001b[1;32mC:\\0_STORAGE\\Programs\\Anaconda3\\envs\\hyper\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(value, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2153\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2154\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   2155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\0_STORAGE\\Programs\\Anaconda3\\envs\\hyper\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m   5079\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m   5080\u001b[0m         \u001b[1;34m\"MaxPool\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5081\u001b[1;33m         data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m   5082\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5083\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\0_STORAGE\\Programs\\Anaconda3\\envs\\hyper\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\0_STORAGE\\Programs\\Anaconda3\\envs\\hyper\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                 instructions)\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mC:\\0_STORAGE\\Programs\\Anaconda3\\envs\\hyper\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3153\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3154\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3155\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3156\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3157\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\0_STORAGE\\Programs\\Anaconda3\\envs\\hyper\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1729\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1730\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1731\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\0_STORAGE\\Programs\\Anaconda3\\envs\\hyper\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1577\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1579\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling1d_2/MaxPool' (op: 'MaxPool') with input shapes: [?,1,1,8]."
     ]
    }
   ],
   "source": [
    "preds, targets = evalute_timeseries(df,window_size,filter_length,nb_filter, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw dxz position prediction with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(preds.shape[0]):\n",
    "    if i>0:\n",
    "        preds[i,0] = preds[i-1,0] + preds[i,0]\n",
    "        preds[i,1] = preds[i-1,1] + preds[i,1]\n",
    "        preds[i,2] = preds[i-1,2] + preds[i,2]\n",
    "        \n",
    "        targets[i,0] = targets[i-1,0] + targets[i,0]\n",
    "        targets[i,1] = targets[i-1,1] + targets[i,1]\n",
    "        targets[i,2] = targets[i-1,2] + targets[i,2]\n",
    "\n",
    "\n",
    "plt.plot(preds[:,0],preds[:,2], label = 'dxz pred')\n",
    "plt.plot(targets[:,0], targets[:,2], label='xz targ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
